# -*- coding: utf-8 -*-
"""loan_defaulter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GCk18DwqhTeT-YTSj5yZ9yVm_R_-FeRw
"""

#import all library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#for show maximum
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

#import google drive
from google.colab import drive
drive.mount('/content/drive')

#import dataset from google drive
bank_df = pd.read_csv('/content/drive/MyDrive/application_data.csv/application_data.csv')
previous_df =pd.read_csv('/content/drive/MyDrive/application_data.csv/previous_application.csv')

#make copy of dataset for safety
bank_df = bank_df.copy()
p_df = previous_df.copy()

Amt_df = bank_df[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE']]

Amt_df.isnull().sum()

from sklearn.impute import SimpleImputer  #import imputer from sklearnlibrary

mean_imputer = SimpleImputer(missing_values = np.nan,strategy = 'mean')
Amt_df['AMT_GOODS_PRICE']=pd.DataFrame(mean_imputer.fit_transform(Amt_df[['AMT_GOODS_PRICE']]))

#see top 5 in dataset
bank_df.head()

bank_df.shape # check rows and column length

bank_df.columns #check All column name

#check null value in dataset and store new variable name msng_info
msng_info = pd.DataFrame(bank_df.isnull().sum().sort_values()).reset_index()
msng_info.rename(columns={'index':'col_name',0:'null_count'},inplace = True) #rename column name
msng_info.head()

msng_info['msng_pct']=msng_info['null_count']/bank_df.shape[0]*100  # add new column msng percentage for chek null value percentage

msng_info

msng_info.to_excel(r"D:\\loan\\missing_info.xlsx",index = False)  # export in excel sheet for better understanding and better view

#create new variable for  that contains  null value more than 40 percent and keep in one list
msng_co = msng_info[msng_info['msng_pct'] >= 40]['col_name'].to_list()
len(msng_co)  #check lentgh of new variable

msng_co

b_msng_rmvd = bank_df.drop(labels = msng_co,axis = 1)  #drop all colums that contains more than 40% null value
b_msng_rmvd.shape

flag_col=[] # using for loop which column statrt with flag these are store in list
for col in b_msng_rmvd.columns:
  if col.startswith('FLAG_'):
    flag_col.append(col)

len(flag_col)

b_msng_rmvd[flag_col].head()

flag_target = b_msng_rmvd[flag_col + ['TARGET']] #create new variable and add flag col with target columns
flag_target.head()

plt.figure(figsize=(20,25))  # create count plot
for i,col in enumerate(flag_col):
  plt.subplot(7,4,i+1)
  sns.countplot(data =flag_target ,x=col,hue = 'TARGET')

flag_corr = ['FLAG_OWN_CAR','FLAG_OWN_REALTY','FLAG_MOBIL','FLAG_EMP_PHONE','FLAG_WORK_PHONE','FLAG_CONT_MOBILE','FLAG_PHONE','FLAG_EMAIL','TARGET']
flag_corr_df = b_msng_rmvd[flag_corr]

flag_corr_df['FLAG_OWN_CAR'] = flag_corr_df['FLAG_OWN_CAR'].replace({'N':0,'Y':1})
flag_corr_df['FLAG_OWN_REALTY'] = flag_corr_df['FLAG_OWN_REALTY'].replace({'N':0,'Y':1})

#chek correlation
corr_df= round(flag_corr_df.corr(),2)

plt.figure(figsize=(10,5))
sns.heatmap(corr_df,cmap='coolwarm',linewidth = 0.5,annot = True)

b_flag_rmvd = b_msng_rmvd.drop(labels =flag_col,axis =1) #remove flag_col columns because no relation between them

b_flag_rmvd.shape

b_flag_rmvd.head()

ext_corr = round(b_flag_rmvd[['EXT_SOURCE_2','EXT_SOURCE_3','TARGET']].corr(),2)

sns.heatmap(ext_corr,cmap = 'coolwarm',linewidth = 0.5,annot = True)

bank_core_rmvd = b_flag_rmvd.drop(labels = ['EXT_SOURCE_2','EXT_SOURCE_3'],axis = 1)

bank_core_rmvd .shape

"""## **Feature Engineering**"""

bank_core_rmvd .head()

bank_core_rmvd .isnull().sum().sort_values()/bank_core_rmvd .shape[0]

bank_core_rmvd .info()

"""## **MISSING IMPUTATION**"""

bank_core_rmvd ['OBS_30_CNT_SOCIAL_CIRCLE'].describe()

bank_core_rmvd ['CNT_FAM_MEMBERS'].isnull().sum()

from sklearn.impute import SimpleImputer  #import imputer from sklearnlibrary

#fill mode value using imputer
imputer = SimpleImputer(missing_values = np.nan,strategy = 'most_frequent')
bank_core_rmvd ['CNT_FAM_MEMBERS']=pd.DataFrame(imputer.fit_transform(bank_core_rmvd [['CNT_FAM_MEMBERS']]))

bank_core_rmvd ['OCCUPATION_TYPE']=pd.DataFrame(imputer.fit_transform(bank_core_rmvd [['OCCUPATION_TYPE']]))

bank_core_rmvd ['OCCUPATION_TYPE'].value_counts()

bank_core_rmvd ['NAME_TYPE_SUITE']=pd.DataFrame(imputer.fit_transform(bank_core_rmvd [['NAME_TYPE_SUITE']]))

bank_core_rmvd ['AMT_ANNUITY'].describe()

mean_imputer = SimpleImputer(missing_values = np.nan,strategy = 'mean')

bank_core_rmvd ['AMT_ANNUITY'] = pd.DataFrame(mean_imputer.fit_transform(bank_core_rmvd [['AMT_ANNUITY']]))

bank_core_rmvd ['AMT_ANNUITY'].isnull().sum()

bank_core_rmvd .info()

bank_core_rmvd ['AMT_REQ_CREDIT_BUREAU_HOUR'].describe()

bank_core_rmvd ['AMT_REQ_CREDIT_BUREAU_HOUR'].unique()

amt_req_col = []
for col in bank_core_rmvd .columns:
  if col.startswith('AMT_REQ_CREDIT_BUREAU'):
    amt_req_col.append(col)

amt_req_col

median_imputer = SimpleImputer(missing_values = np.nan,strategy = 'median')

for col in amt_req_col:
  bank_core_rmvd [col]=pd.DataFrame(median_imputer.fit_transform(bank_core_rmvd [[col]]))

bank_core_rmvd .isnull().sum()

bank_core_rmvd ['AMT_GOODS_PRICE'].agg(['min','median','max'])

bank_core_rmvd ['AMT_GOODS_PRICE']=pd.DataFrame(median_imputer.fit_transform(bank_core_rmvd [['AMT_GOODS_PRICE']]))

circle_col = []
for col in bank_core_rmvd .columns:
  if col.endswith("CIRCLE"):
    circle_col.append(col)

circle_col

for col in circle_col:
  bank_core_rmvd [col]=pd.DataFrame(mean_imputer.fit_transform(bank_core_rmvd [[col]]))

"""## **VALUE MODIFICATION**"""

bank_core_rmvd .head()

days_col = []
for col in bank_core_rmvd .columns:
  if col.startswith('DAYS'):
    days_col.append(col)


days_col

for col in days_col:
  bank_core_rmvd [col] = abs(bank_core_rmvd [col])

bank_core_rmvd .head()

bank_core_rmvd .nunique().sort_values()

"""## **Outlier detection and treatment**"""

bank_core_rmvd ['AMT_GOODS_PRICE'].agg(['min','max','median'])

sns.kdeplot(data=bank_core_rmvd ,x ='AMT_GOODS_PRICE')

sns.boxenplot(data=bank_core_rmvd ,x ='AMT_GOODS_PRICE')

bank_core_rmvd ['AMT_GOODS_PRICE'].quantile([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])

Q1 = bank_core_rmvd ['AMT_GOODS_PRICE'].quantile(0.25)

Q3 = bank_core_rmvd ['AMT_GOODS_PRICE'].quantile(0.75)

IQR = Q3-Q1

lower_limit = Q1 - 1.5*IQR
upper_limit = Q3 + 1.5*IQR

bin = [0,100000,200000,300000,400000,500000,600000,700000,800000,900000,4050000]
range =['0-100k','100k-200k','200k-300k','300k-400k','400k-500k','500k-600k','600k-700k','700k-800k','800k-900k','above 900k']

bank_core_rmvd ['AMT_GOODS_PRICE'] = pd.cut(bank_core_rmvd ['AMT_GOODS_PRICE'],bin,labels = range)

bank_core_rmvd ['AMT_GOODS_PRICE'].value_counts().sort_index()

sns.boxenplot(data = bank_core_rmvd ,x='AMT_INCOME_TOTAL')

sns.kdeplot(data = bank_core_rmvd ,x='AMT_INCOME_TOTAL')

bank_core_rmvd ['AMT_INCOME_TOTAL'].quantile([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])

bank_core_rmvd ['AMT_INCOME_TOTAL'].agg(['max'])

bank_core_rmvd ['AMT_CREDIT'] = pd.to_numeric(bank_core_rmvd ['AMT_CREDIT'], errors='coerce')

bins = [0, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 117000000]
new_range = ['0-100k', '100k-150k', '150k-200k', '200k-250k', '250k-300k', '300k-350k', '350k-400k', 'above 400k']

bank_core_rmvd ['AMT_INCOME_TOTAL'] = pd.cut(bank_core_rmvd ['AMT_INCOME_TOTAL'], bins, labels=new_range)

bank_core_rmvd ['AMT_INCOME_TOTAL'].isnull().sum()

bank_core_rmvd .info()

bank_core_rmvd .head()

bank_core_rmvd .groupby(['AMT_INCOME_TOTAL']).size()

bank_core_rmvd ['AMT_CREDIT'].quantile([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])

bin = [0,200000,400000,600000,800000,900000,1000000,2000000,3000000,4050000]
new_range =['0-200k','200k-400k','400k-600k','600k-800k','800k-900k','900k-1M','1M-2M','2M-3M','above 3M']

bank_core_rmvd ['AMT_CREDIT'] = pd.cut(bank_core_rmvd ['AMT_CREDIT'],bin,labels = new_range)

bank_core_rmvd ['AMT_CREDIT'].isnull().sum()

bank_core_rmvd .groupby(['AMT_CREDIT']).size()

bank_core_rmvd ['AMT_ANNUITY'].quantile([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99])

bank_core_rmvd ['AMT_ANNUITY'].agg(['max'])

bin = [0,10000,20000,30000,40000,50000,60000,70000,258026]
range =['0-10k','10k-20k','20k-30k','30k-40k','40k-50k','50k-60k','60k-70k','above 70k']

bank_core_rmvd ['AMT_ANNUITY'] = pd.cut(bank_core_rmvd ['AMT_ANNUITY'],bin,labels = range)

bank_core_rmvd.groupby(['AMT_ANNUITY']).size()

bank_core_rmvd[bank_core_rmvd['DAYS_EMPLOYED']< bank_core_rmvd['DAYS_EMPLOYED'].max()].max()['DAYS_EMPLOYED']

bins = [0,1825,3650,5475,7300,9125,10950,12775,14600,16425,18250,365243]

range =['0-5Y','5Y-10Y','10Y-15Y','15Y-20Y','20Y-25Y','25Y-30Y','30Y-35Y','35Y-40Y','40Y-45Y','45Y-50Y','Above-50Y']

bank_core_rmvd['DAYS_EMPLOYED'] = pd.cut(bank_core_rmvd['DAYS_EMPLOYED'],bins,labels = range)

bank_core_rmvd['DAYS_EMPLOYED'].isnull().sum()

bins = [0,7300,10950,14600,18250,21900,25229]

range =['20Y','20Y-30Y','30Y-40Y','40Y-50Y','50Y-60Y','Above 60Y']

bank_core_rmvd['DAYS_BIRTH'] = pd.cut(bank_core_rmvd['DAYS_BIRTH'],bins,labels = range)

bank_core_rmvd['DAYS_BIRTH'].isnull().sum()

"""## **DATA ANALYSIS**"""

bank_score_df = bank_core_rmvd.copy()

bank_core_rmvd.dtypes.value_counts()

obj_var = bank_core_rmvd.select_dtypes(include="object").columns
obj_var

bank_core_rmvd.groupby(['NAME_CONTRACT_TYPE']).size()



plt.figure(figsize=(8,4))
sns.countplot(data=bank_core_rmvd,x = 'NAME_CONTRACT_TYPE',hue = "TARGET")

data_percentage = bank_core_rmvd[['NAME_CONTRACT_TYPE','TARGET']].groupby(['NAME_CONTRACT_TYPE'],as_index = False).mean()
data_percentage['Percentage'] = data_percentage['TARGET']*100

data_percentage

sns.barplot(data =data_percentage,x='NAME_CONTRACT_TYPE',y ='Percentage')

plt.figure(figsize=(10,5))

plt.subplot(1,2,1)
sns.countplot(data=bank_core_rmvd,x = 'NAME_CONTRACT_TYPE',hue = "TARGET")

plt.subplot(1,2,2)
sns.barplot(data =data_percentage,x='NAME_CONTRACT_TYPE',y ='Percentage')
plt.subplots_adjust(hspace=0.25)
plt.show()

bank_core_rmvd["CODE_GENDER"].value_counts()

plt.figure(figsize=(10,4))
sns.countplot(data =bank_core_rmvd,x='CODE_GENDER',hue = 'TARGET')

data_percentage = bank_core_rmvd[["CODE_GENDER","TARGET"]].groupby(["CODE_GENDER"],as_index = False).mean()
data_percentage["Percentage"]=data_percentage["TARGET"]*100

data_percentage

sns.barplot(data = data_percentage,x='CODE_GENDER',y='Percentage')

plt.figure(figsize=(10,5))

plt.subplot(1,2,1)
sns.countplot(data=bank_core_rmvd,x = 'CODE_GENDER',hue = "TARGET")

plt.subplot(1,2,2)
sns.barplot(data =data_percentage,x='CODE_GENDER',y ='Percentage')
plt.subplots_adjust(hspace=0.25)
plt.show()

bank_core_rmvd.groupby(["NAME_TYPE_SUITE"]).size()

sns.countplot(data = bank_core_rmvd,x='NAME_TYPE_SUITE',hue ="TARGET")
plt.xticks(rotation = 90)

data_percentage = bank_core_rmvd[["NAME_TYPE_SUITE","TARGET"]].groupby(["NAME_TYPE_SUITE"],as_index=False).mean()
data_percentage["Percentage"] = data_percentage["TARGET"]*100

data_percentage

sns.barplot(data =data_percentage,x='NAME_TYPE_SUITE',y = "Percentage")
plt.xticks(rotation = 90)

plt.figure(figsize=(20,96))
for i,var in enumerate(obj_var):
  data_percentage = bank_core_rmvd[[var,"TARGET"]].groupby([var],as_index=False).mean()
  data_percentage["Percentage"] = data_percentage["TARGET"]*100
  plt.subplot(10,2,i+i+1)
  sns.countplot(data=bank_core_rmvd,x = var,hue = "TARGET")
  plt.xticks(rotation = 90)

  plt.subplot(10,2,i+i+2)
  sns.barplot(data =data_percentage,x=var,y ='Percentage',palette='coolwarm')
  plt.subplots_adjust(hspace=0.5)
  plt.xticks(rotation = 90)

bank_core_rmvd['NAME_TYPE_SUITE'].value_counts()

Bank_score_rmvd_df = pd.concat([bank_core_rmvd, Amt_df], axis=1)

Bank_score_rmvd_df.head()

Bank_score_rmvd_df.dtypes.value_counts()

num_var = Bank_score_rmvd_df.select_dtypes(include =['int64','float64']).columns
num_cat_var = Bank_score_rmvd_df.select_dtypes(include =['int64','float64','category']).columns

len(num_var)

num_data = Bank_score_rmvd_df[num_var]

defaulter = num_data[num_data['TARGET']==1]
Repayers = num_data[num_data['TARGET']==0]

num_data.groupby('TARGET').size()/num_data.shape[0]*100

defaulter.corr()

defaulter_corrs = defaulter.corr()
defaulter_corrs_unstack = defaulter_corrs.where(np.triu(np.ones(defaulter_corrs.shape),k = 1 ).astype(np.bool)).unstack().reset_index().rename(columns={'level_0':'Var1','level_1':'Var2',0:'Corre'})

defaulter_corrs_unstack['Corre']=abs(defaulter_corrs_unstack['Corre'])
defaulter_corrs_unstack.dropna(subset=['Corre']).sort_values(by = 'Corre',ascending = False)

repayers_corr = Repayers.corr()

repayers_corr_unstack = repayers_corr.where(np.triu(np.ones(repayers_corr.shape),k=1).astype(np.bool)).unstack().reset_index().rename(columns={'level_0':'var1','level_1':'var',0:'corr'})
repayers_corr_unstack['corr']=abs(repayers_corr_unstack['corr'])
repayers_corr_unstack.dropna(subset=['corr'] ).sort_values(by = ['corr'],ascending = False)

num_data.rename(columns={"AMT_GOODS_PRICE":"AMT_GOODS_PRICE_RANGE",},inplace = True)

num_data.head()

num_data.head()

columns_to_rename_indices = [34]  # Replace with the  indices
new_column_names = ['AMT_GOODS_PRICE']  # Replace with the  new names

# Rename the specified columns by index
for index, new_name in zip(columns_to_rename_indices, new_column_names):
    num_data.columns.values[index] = new_name

columns_to_rename_indices = [27,29,31]  # Replace with the indices
new_column_names = ['AMT_INCOME_TOTAL_RANGE','AMT_CREDIT_RANGE','AMT_ANNUITY_RANGE']  # Replace with the  new names

# Rename the specified columns by index
for index, new_name in zip(columns_to_rename_indices, new_column_names):
    num_data.columns.values[index] = new_name

num_data.head()

"""### **UNIVARIANTE ANALYSIS**"""

Amt_var = ['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE']

plt.figure(figsize = (20,15))
for i,var in enumerate(Amt_var):
  plt.subplot(4,2,i+1)
  sns.kdeplot(data=num_data,x =var,hue = 'TARGET')

"""### **BIVARIANTE ANALYSIS**"""

sns.scatterplot(data=num_data,x='AMT_CREDIT',y ='AMT_GOODS_PRICE',hue = 'TARGET' )

sns.scatterplot(data=num_data,x='AMT_CREDIT',y ='AMT_INCOME_TOTAL',hue = 'TARGET' )

sns.kdeplot(data =num_data,x='AMT_CREDIT',y='CNT_CHILDREN',hue ='TARGET')

amt_var = num_data[['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE','TARGET']]

sns.pairplot(data = amt_var, hue = 'TARGET')

null_count_previous = pd.DataFrame(p_df.isnull().sum().sort_values(ascending = False)/p_df.shape[0]*100).reset_index().rename(columns={'index':'var',0:'countpercentage'})

null_count_previous

var_msng_40 = list(null_count_previous[null_count_previous['countpercentage'] >= 40]['var'])

var_msng_40

nva_cols = var_msng_40 + ['WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START','FLAG_LAST_APPL_PER_CONTRACT','NFLAG_LAST_APPL_IN_DAY']

p_df_remove_nva_cols = p_df.drop(labels = nva_cols,axis = 1)

p_df_remove_nva_cols.head()

p_df_remove_nva_cols.isnull().sum().sort_values(ascending = False)/p_df_remove_nva_cols.shape[0]*100

p_df_remove_nva_cols['AMT_GOODS_PRICE'].agg(func = ['mean','median'])

sns.boxplot(data = p_df_remove_nva_cols,x ='AMT_GOODS_PRICE')

from sklearn.impute import SimpleImputer

mode_imputer = SimpleImputer(missing_values = np.nan,strategy ='most_frequent')

p_df_remove_nva_cols['AMT_GOODS_PRICE'] =pd.DataFrame(mode_imputer.fit_transform(p_df_remove_nva_cols[['AMT_GOODS_PRICE']]))

p_df_remove_nva_cols['AMT_GOODS_PRICE'].isnull().sum()

p_df_remove_nva_cols['AMT_ANNUITY'].agg(['mean','median','max'])

p_df_remove_nva_cols['AMT_ANNUITY'] = pd.DataFrame(mode_imputer.fit_transform(p_df_remove_nva_cols[['AMT_ANNUITY']]))

p_df_remove_nva_cols['PRODUCT_COMBINATION'].head()

p_df_remove_nva_cols['PRODUCT_COMBINATION'] = pd.DataFrame(mode_imputer.fit_transform(p_df_remove_nva_cols[['PRODUCT_COMBINATION']]))

p_df_remove_nva_cols[p_df_remove_nva_cols['CNT_PAYMENT'].isnull()].groupby(['NAME_CONTRACT_STATUS']).size().sort_values(ascending = False)

p_df_remove_nva_cols['CNT_PAYMENT'] = p_df_remove_nva_cols['CNT_PAYMENT'].fillna(0)

p_df_remove_nva_cols.isnull().sum()

len(p_df_remove_nva_cols.columns)

merge_df = pd.merge(Bank_score_rmvd_df,p_df_remove_nva_cols,how = 'inner',on = 'SK_ID_CURR')

merge_df.head(10)

Bank_score_rmvd_df.head()

plt.figure(figsize=(15,6))

sns.countplot(data = merge_df,x= 'NAME_CASH_LOAN_PURPOSE',hue = 'NAME_CONTRACT_STATUS')
plt.xticks(rotation = 90)
plt.yscale('log')

sns.countplot(data = merge_df,x= 'NAME_CONTRACT_STATUS',hue = 'TARGET')

merged_agg = merge_df.groupby(['NAME_CONTRACT_STATUS','TARGET']).size().reset_index().rename(columns={0 :'COUNT'})
sum_df = merged_agg.groupby(['NAME_CONTRACT_STATUS'])['COUNT'].sum().reset_index()

sum_df

merged_agg2 = pd.merge(merged_agg,sum_df,how='left',on='NAME_CONTRACT_STATUS')

merged_agg2['Percentage'] = round((merged_agg2['COUNT_x']/merged_agg2['COUNT_y'])*100,2)

merged_agg2

